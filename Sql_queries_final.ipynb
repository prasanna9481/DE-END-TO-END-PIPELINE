{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8nNuIRu8Eun"
      },
      "source": [
        "### Create DuckDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2u0aEnC8Euo",
        "outputId": "3fdfe36b-6418-4f75-dc67-7db559095109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DuckDB database and table created successfully.\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "\n",
        "# Create a new DuckDB database (or connect to an existing one)\n",
        "conn = duckdb.connect('cleaned_redshift_data_001.duckdb')\n",
        "\n",
        "# Define the schema and create the table\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE queries (\n",
        "    instance_id VARCHAR,\n",
        "    cluster_size INTEGER,\n",
        "    user_id VARCHAR,\n",
        "    database_id VARCHAR,\n",
        "    query_id VARCHAR,\n",
        "    arrival_timestamp TIMESTAMP,\n",
        "    compile_duration_ms INTEGER,\n",
        "    queue_duration_ms INTEGER,\n",
        "    execution_duration_ms INTEGER,\n",
        "    feature_fingerprint VARCHAR,\n",
        "    was_aborted BOOLEAN,\n",
        "    was_cached BOOLEAN,\n",
        "    cache_source_query_id VARCHAR,\n",
        "    query_type VARCHAR,\n",
        "    num_permanent_tables_accessed INTEGER,\n",
        "    num_external_tables_accessed INTEGER,\n",
        "    num_system_tables_accessed INTEGER,\n",
        "    read_table_ids VARCHAR,\n",
        "    write_table_ids VARCHAR,\n",
        "    mbytes_scanned INTEGER,\n",
        "    mbytes_spilled INTEGER,\n",
        "    num_joins INTEGER,\n",
        "    num_scans INTEGER,\n",
        "    num_aggregations INTEGER\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query to create the table\n",
        "conn.execute(create_table_query)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n",
        "\n",
        "print(\"DuckDB database and table created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTfDJkTV8Eur",
        "outputId": "22ce956b-a631-4df2-e7fd-ef1615788f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  user_id      month  total_data_scanned_mb  total_queries_executed\n",
            "0       0 2024-05-01            702669359.0                   22336\n",
            "1       2 2024-05-01              5179000.0                     165\n",
            "2       1 2024-05-01              3101471.0                    2435\n",
            "3       5 2024-05-01              1196376.0                      18\n",
            "4       4 2024-05-01               384090.0                      39\n"
          ]
        }
      ],
      "source": [
        "import duckdb\n",
        "\n",
        "# Connection to DuckDB database\n",
        "conn = duckdb.connect('cleaned_redshift_data_001.duckdb')\n",
        "\n",
        "# Table to store the cost per query\n",
        "query =  \"\"\"SELECT user_id,\n",
        "    DATE_TRUNC('month', arrival_timestamp) AS month,\n",
        "    SUM(mbytes_scanned) AS total_data_scanned_mb,\n",
        "    COUNT(query_id) AS total_queries_executed\n",
        "\n",
        "FROM queries\n",
        "GROUP BY user_id, DATE_TRUNC('month', arrival_timestamp)\n",
        "ORDER BY month DESC, total_data_scanned_mb DESC\n",
        "LIMIT 5;\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Execute the query and fetch results\n",
        "result = conn.execute(query).fetchdf()  # Fetch result as a DataFrame\n",
        "\n",
        "# Print the results\n",
        "print(result)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "# Connect to DuckDB database\n",
        "conn = duckdb.connect('cleaned_redshift_data_001.duckdb')\n",
        "\n",
        "# SQL query to fetch data\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    user_id,\n",
        "    DATE_TRUNC('month', arrival_timestamp) AS month,\n",
        "    SUM(mbytes_scanned) AS total_data_scanned_mb,\n",
        "    COUNT(query_id) AS total_queries_executed\n",
        "FROM\n",
        "    queries\n",
        "GROUP BY\n",
        "    user_id, DATE_TRUNC('month', arrival_timestamp)\n",
        "ORDER BY\n",
        "    month DESC, total_data_scanned_mb DESC\n",
        "LIMIT 5;\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and fetch results as a DataFrame\n",
        "result = conn.execute(query).fetchdf()  # Fetch result as a Pandas DataFrame\n",
        "\n",
        "# Print the results\n",
        "print(result)\n",
        "\n",
        "# Save the result as JSON\n",
        "result.to_json(\"query_results.json\", orient=\"records\", date_format=\"iso\")  # JSON file\n",
        "\n",
        "# Save the result as CSV\n",
        "result.to_csv(\"query_results.csv\", index=False)  # CSV file\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n",
        "\n",
        "print(\"Query results saved as 'query_results.json' and 'query_results.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkbIu19UhMPr",
        "outputId": "15d8441e-7b78-4368-d761-33e0e9d571c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  user_id      month  total_data_scanned_mb  total_queries_executed\n",
            "0       0 2024-05-01            702669359.0                   22336\n",
            "1       2 2024-05-01              5179000.0                     165\n",
            "2       1 2024-05-01              3101471.0                    2435\n",
            "3       5 2024-05-01              1196376.0                      18\n",
            "4       4 2024-05-01               384090.0                      39\n",
            "Query results saved as 'query_results.json' and 'query_results.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kqrcvm7xUwFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "\n",
        "# Connect to DuckDB database\n",
        "conn = duckdb.connect('cleaned_redshift_data_001.duckdb')\n",
        "\n",
        "query = \"\"\"select query_id , instance_id from queries where query_id = 143296;\"\"\"\n",
        "\n",
        "# Execute the query and fetch results\n",
        "result = conn.execute(query).fetchdf()  # Fetch result as a DataFrame\n",
        "\n",
        "# Print the results\n",
        "print(result)\n",
        "\n",
        "\n",
        "\n",
        "# Query 2: Create the `cost_estimation` table\n",
        "query2 = \"\"\"\n",
        "CREATE TABLE IF NOT EXISTS cost_estimation (\n",
        "    query_id  VARCHAR PRIMARY KEY,\n",
        "    user_id VARCHAR,\n",
        "    cluster_size INTEGER,\n",
        "    arrival_timestamp TIMESTAMP,\n",
        "    execution_duration_ms INTEGER,\n",
        "    mbytes_scanned INTEGER,\n",
        "    mbytes_spilled INTEGER,\n",
        "    total_execution_cost DECIMAL(10, 4),\n",
        "    total_scan_cost DECIMAL(10, 4),\n",
        "    total_spill_cost DECIMAL(10, 4),\n",
        "    total_cost DECIMAL(10, 4)\n",
        ");\n",
        "\"\"\"\n",
        "conn.execute(query2)\n",
        "\n",
        "# Query 3: Insert the cost data into `cost_estimation` (assume cost calculations are done separately)\n",
        "query3 = \"\"\"\n",
        "INSERT INTO cost_estimation (\n",
        "    query_id, user_id, cluster_size, arrival_timestamp,\n",
        "    execution_duration_ms, mbytes_scanned, mbytes_spilled,\n",
        "    total_execution_cost, total_scan_cost, total_spill_cost, total_cost\n",
        ")\n",
        "SELECT\n",
        "    q.query_id ||'_'||q.instance_id,\n",
        "    q.user_id,\n",
        "    q.cluster_size,\n",
        "    q.arrival_timestamp,\n",
        "    q.execution_duration_ms,\n",
        "    q.mbytes_scanned,\n",
        "    q.mbytes_spilled,\n",
        "    ROUND(q.execution_duration_ms / 1000 * 0.000138, 4) AS total_execution_cost,\n",
        "    ROUND(q.mbytes_scanned / 1024 * 0.03, 4) AS total_scan_cost,\n",
        "    ROUND(q.mbytes_spilled / 1024 * 0.02, 4) AS total_spill_cost,\n",
        "    ROUND(\n",
        "        ROUND(q.execution_duration_ms / 1000 * 0.000138, 4) +\n",
        "        ROUND(q.mbytes_scanned / 1024 * 0.03, 4) +\n",
        "        ROUND(q.mbytes_spilled / 1024 * 0.02, 4),\n",
        "        4\n",
        "    ) AS total_cost\n",
        "FROM queries q;\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "result = conn.execute(query3).fetchdf()  # Fetch result as a DataFrame\n",
        "\n",
        "# Print the results\n",
        "print(result)\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87IkZMlXgdKP",
        "outputId": "daf46454-8476-42f5-b26f-8e12ff9dfbde"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  query_id instance_id\n",
            "0   143296         104\n",
            "   Count\n",
            "0  82444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "\n",
        "# Connect to DuckDB database\n",
        "conn = duckdb.connect('cleaned_redshift_data_001.duckdb')\n",
        "\n",
        "query = \"\"\"select * from queries where query_id = 143296;\"\"\"\n",
        "\n",
        "# Execute the query and fetch results\n",
        "result = conn.execute(query).fetchdf()  # Fetch result as a DataFrame\n",
        "\n",
        "# Print the results\n",
        "print(result)\n",
        "\n",
        "# Close the connection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HELVb9WYr-_P",
        "outputId": "aea5ee6c-7ae4-4965-b5a2-80b84ddc7c2e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  instance_id  cluster_size user_id database_id query_id  \\\n",
            "0         104           NaN       0           0   143296   \n",
            "\n",
            "           arrival_timestamp  compile_duration_ms  queue_duration_ms  \\\n",
            "0 2024-03-01 00:02:17.633593               760245                  0   \n",
            "\n",
            "   execution_duration_ms                                feature_fingerprint  \\\n",
            "0                 780366  f93d7a158afa58c0981874d43045b0978c5da8a0d7accf...   \n",
            "\n",
            "   ...  num_permanent_tables_accessed  num_external_tables_accessed  \\\n",
            "0  ...                              2                             0   \n",
            "\n",
            "  num_system_tables_accessed read_table_ids  write_table_ids  mbytes_scanned  \\\n",
            "0                          0              6             None          124716   \n",
            "\n",
            "   mbytes_spilled num_joins num_scans  num_aggregations  \n",
            "0               0         1         2                 3  \n",
            "\n",
            "[1 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "conn = duckdb.connect('cleaned_redshift_data_001.duckdb')\n",
        "# SQL Query to identify tables used only in JOINs\n",
        "query = \"\"\"\n",
        "WITH exploded_tables AS (\n",
        "    SELECT\n",
        "        query_id,\n",
        "        num_joins,\n",
        "        UNNEST(SPLIT(read_table_ids, ',')) AS table_id\n",
        "    FROM\n",
        "        queries\n",
        "    WHERE\n",
        "        read_table_ids IS NOT NULL\n",
        "),\n",
        "join_usage AS (\n",
        "    SELECT\n",
        "        table_id,\n",
        "        COUNT(*) AS join_count\n",
        "    FROM\n",
        "        exploded_tables\n",
        "    WHERE\n",
        "        num_joins > 0\n",
        "    GROUP BY\n",
        "        table_id\n",
        "),\n",
        "total_usage AS (\n",
        "    SELECT\n",
        "        table_id,\n",
        "        COUNT(*) AS total_count\n",
        "    FROM\n",
        "        exploded_tables\n",
        "    GROUP BY\n",
        "        table_id\n",
        "),\n",
        "usage_analysis AS (\n",
        "    SELECT\n",
        "        t.table_id,\n",
        "        t.total_count,\n",
        "        j.join_count,\n",
        "        (j.join_count * 1.0 / t.total_count) AS join_usage_ratio\n",
        "    FROM\n",
        "        total_usage t\n",
        "    LEFT JOIN\n",
        "        join_usage j\n",
        "    ON\n",
        "        t.table_id = j.table_id\n",
        ")\n",
        "SELECT\n",
        "    table_id,\n",
        "    total_count,\n",
        "    join_count,\n",
        "    join_usage_ratio\n",
        "FROM\n",
        "    usage_analysis\n",
        "WHERE\n",
        "    join_usage_ratio = 1.0\n",
        "ORDER BY\n",
        "    total_count DESC;\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and fetch the results\n",
        "result = conn.execute(query).fetchdf()\n",
        "\n",
        "# Save the result as a JSON file\n",
        "output_json_file = '/tables_only_used_in_joins.json'\n",
        "result.to_json(output_json_file, orient=\"records\")\n",
        "\n",
        "# Print the results and file path\n",
        "print(\"Query executed successfully!\")\n",
        "print(f\"Results saved to: {output_json_file}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fq56EGyUxH9",
        "outputId": "846e35b9-6e01-4703-c27c-9bcc0a8fc96f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query executed successfully!\n",
            "Results saved to: /tables_only_used_in_joins.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# SQL Query to calculate execution time per query type\n",
        "query = \"\"\"\n",
        "SELECT\n",
        "    query_type,\n",
        "    COUNT(*) AS query_count,\n",
        "    SUM(execution_duration_ms) AS total_execution_time_ms,\n",
        "    AVG(execution_duration_ms) AS average_execution_time_ms\n",
        "FROM\n",
        "    queries\n",
        "GROUP BY\n",
        "    query_type\n",
        "ORDER BY\n",
        "    total_execution_time_ms DESC;\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query and fetch the results\n",
        "result = conn.execute(query).fetchdf()\n",
        "print(result)\n",
        "# Save the result as a JSON file\n",
        "output_json_file = '/query_type_execution_time.json'\n",
        "result.to_json(output_json_file, orient=\"records\")\n",
        "\n",
        "# Print the results and file path\n",
        "print(\"Query executed successfully!\")\n",
        "print(f\"Results saved to: {output_json_file}\")\n",
        "\n",
        "# Close the connection\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKupwJCJYWbN",
        "outputId": "302c6141-a437-4741-d0a4-147ea138f57c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  query_type  query_count  total_execution_time_ms  average_execution_time_ms\n",
            "0     select        21647              318336220.0               14705.789255\n",
            "1     insert        29754              223870189.0                7524.036735\n",
            "2     delete         7433              174988219.0               23542.071707\n",
            "3       copy        10543              121621747.0               11535.781751\n",
            "4     update          200               35616582.0              178082.910000\n",
            "5       ctas         1281               32901215.0               25684.008587\n",
            "6      other         6261               22507397.0                3594.856572\n",
            "7     vacuum          155               21001070.0              135490.774194\n",
            "8    analyze         3445                6369264.0                1848.842961\n",
            "9     unload         1725                3776547.0                2189.302609\n",
            "Query executed successfully!\n",
            "Results saved to: /query_type_execution_time.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
